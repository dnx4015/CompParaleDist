\documentclass[a4paper,12pt,fleqn]{article}
%\usepackage {psfig,epsfig} % para incluir figuras em PostScript
\usepackage{amsfonts,amsthm,amsopn,amssymb,latexsym}
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage{geometry}
\usepackage[utf8]{inputenc}
\usepackage[intlimits]{amsmath}

% formato de codigo
\usepackage{listings}
\lstset{
 	breaklines=true,
	basicstyle=\scriptsize,
	language=C++,
	numbers=left,
	numbersep=-10pt,
	stepnumber=1,
	tabsize=2
}

%alguns macros
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\Rn}{{\ensuremath{\mathbb{R}}}^{n}}
\newcommand{\Rm}{{\ensuremath{\mathbb{R}}}^{m}}
\newcommand{\Rmn}{{\ensuremath{\mathbb{R}}}^{{m}\times{n}}}
\newcommand{\contcaption}[1]{\vspace*{-0.6\baselineskip}\begin{center}#1\end{center}\vspace*{-0.6\baselineskip}}
%=======================================================================
% Dimensões da página
\usepackage{a4}                       % tamanho da página
\setlength{\textwidth}{16.0cm}        % largura do texto
\setlength{\textheight}{9.0in}        % tamanho do texto (sem head, etc)
\renewcommand{\baselinestretch}{1.15} % espaçamento entrelinhas
\addtolength{\topmargin}{-1cm}        % espaço entre o head e a margem
\setlength{\oddsidemargin}{-0.1cm}    % espaço entre o texto e a margem
       
% Ser indulgente no preenchimento das linhas
\sloppy
 

\begin{document}


\pagestyle {empty}

\include {capa}

  
\pagestyle {empty}
\abstract{Nesse Exercício Programa (EP) o objetivo foi explorar a computação paralela com memoria compartilhada, para isso foi usado o padrão OpenMP.
A primeira parte do trabalho explora o cuidado que deve-se ter no momento de realizar o desenvolvimento de programas usando as diretivas do OpenMP. É muito simples cometer erros quando ainda se está pensando de maneira sequencial, ao assumir algum comportamento ou quando não se conhece bem o comportamento padrão das diretivas usadas.
A segunda parte do EP procura avaliar as melhoras (ou falta delas) no tempo de execução de um programa alvo, mult.c, que realiza a multiplicação de 2 matrizes. Para avaliar o desempenho da versão sequencial versus a paralela uma serie de experimentos foram realizados. Alguns deles involucraram a alteração do programa para criar distintas zonas paralelas e também a execução deles usando diferentes números de threads.
A continuação presentamos os experimentos, resultados e conclusões.}

\newpage 
 
\tableofcontents 
 
 
% Numeração em romanos para páginas iniciais (sumários, listas, etc) 
%\pagenumbering {roman} 
\pagestyle {plain} 
 
 
 
\setcounter{page}{0} \pagenumbering{arabic} 
 
 
 
 
 
 
  
\setlength{\parindent}{0in}  %espaço entre paragrafo e margem 
% Espaçamento entre parágrafos 
\parskip 5pt   
 \clearpage 
 
\section{Introdução} 
A computação paralela consiste em executar um conjunto de cálculos de maneira simultânea ~\cite{Gottlieb89}. A meta de este tipo de computação é diminuir o tempo de execução que exigem algumas aplicações, e.g. aquelas com fortes requerimentos de computo. Atualmente, existem computadores com múltiplos cores; além de isso também contam com tecnologias como hyper-threading, o que gera que o sistema operativo assuma que conta com uma maior quantidade de recursos de computo. Os recursos, por tanto, estão prontos para ser usados. Porém, para realmente obter uma melhoria no rendimento não é suficiente executar as aplicações em uma máquina multicore, é necessário que elas troquem seus algoritmos sequências por uma versão paralela. De outra maneira, não estaria-se fazendo uso do processamento paralelo e seus benefícios.  

O grande problema é que a troca de algoritmos sequências por paralelos não é um trabalho simples. Existem diversos problemas na geração de códigos paralelos de bom rendimento, alguns deles são ~\cite{Matloff14}: 
\begin{itemize} 
\item Gargalos de comunicação. Debe ter-se em consideração a quantidade processadores que serão utilizados na execução e o overhead produto da comunicação entre estes processadores e a memoria~\cite{Gebali11}. Isto é importante pois pode acontecer que um programa em versão paralela tome mais tempo na execução do que na versão sequencial. O que se debe a que a memoria só pode ser acessada por um thread em qualquer momento e o custo de manter as caches de cada processador coerente também gera um overhead. 
\item Balanceamento de carga. Ao fazer uma divisão de trabalho o ideal é que cada uma das partes tenha uma carga igual. Se uma delas tem mais trabalho do que as outras então no final o problema volta a ser sequencial pois a maioria termina com sua carga e umas poucas continuam com o resto do trabalho. 
\item Problemas na construção do código. Os desenvolvedores estão acostumados a pensar em forma sequencial e por tanto é muito fácil cometer erros de 
concorrência. As operações simples, como por exemplo a assinação de valores a uma variável, causam resultados inesperados na versão paralela. Isto é devido as condições de corrida, i.e. quando o programa se desenvolve em um ordem diferente ao que o programador planeio. 
\end{itemize} 
 Para evitar os erros produzidos por o pouco cuidado do desenvolvedor e para maximizar o paralelismo dos algoritmos que são sequências existem conjuntos de diretivas que criam um código paralelo executável. OpenMP é um conjunto de diretivas para o compilar, rutinas de libraria e variáveis de entorno que podem ser usadas para a geração de paralelismo em códigos Fortran e C/C++ ~\cite{OpenMP13}. O objetivo é garantir o correto funcionamento dos programas e obter os benefícios do paralelismo. 
 
Neste trabalho exploramos os problemas persistentes no uso das diretivas do OpenMP. Tanto no desenvolvimento de código errôneo, como na geração de overhead pela geração de áreas paralelas ineficientes. Para isso desenvolvemos experimentos para obter o tempo promédio na execução de códigos gerados a partir de distintas áreas paralelas, em ambientes diferentes e com distintas quantidades de threads. 
 
\section{Exercício 1} 
\textbf{Escolher um código na internet que use as diretivas de compilação do OpenMP, esse código deve ser procurado nos respetivos tutoriais e manuais desse padrão de programação multiprocessamento. A ideia e encontrar erros nessas implementações fornecidas ou apresentadas nos tutoriais consultados. Apresente o código, aponte os problemas e descreva quais são as correções feitas para tirar o erro da aplicação.} 
 
\subsection{Código com erro} 
	O seguinte programa foi extraído de \cite{Rogerio15} e tem como objetivo imprimir os valores de $A[ i ] = i * i$ no mesmo ordem da iteração, neste caso para os valores de $i$ a partir de 0 a 15.

	\begin{lstlisting} 
		#include <stdio.h>
		#include <omp.h>
		#define SIZE 16

		int main(){
			int A[ SIZE ] , i ;
			#pragma omp parallel for schedule( static , 2 ) num_threads( 4 ) ordered
			for( i = 0 ; i < SIZE ; i++){
				A[ i ] = i * i ;
				printf( "Th[ %d ]: %02d = %03d\n" , omp_get_thread_num() , i , A[ i ] ) ;
			}
			return 0 ;
		}
	\end{lstlisting}
	
	O resultado sería:
	\begin{verbatim}
		Th[ 0 ]: 00 = 000
		Th[ 0 ]: 01 = 001
		Th[ 1 ]: 02 = 004
		Th[ 1 ]: 03 = 009
		Th[ 2 ]: 04 = 016
		Th[ 2 ]: 05 = 025
		Th[ 3 ]: 06 = 036
		Th[ 3 ]: 07 = 049
		Th[ 0 ]: 08 = 064
		Th[ 0 ]: 09 = 081
		Th[ 1 ]: 10 = 100
		Th[ 1 ]: 11 = 121
		Th[ 2 ]: 12 = 144
		Th[ 2 ]: 13 = 169
		Th[ 3 ]: 14 = 196
		Th[ 3 ]: 15 = 225
	\end{verbatim}
 
 \subsection{Problemas encontrados} 
 	O erro no programa anterior está em usar a \textbf{diretiva  ordered} sem colocar um \textbf{bloco ordered} dentro de for (linhas 9-10) \cite{Lawrence14}. Por isso que ao executar o programa, o resultado será similar a:
	\begin{verbatim} 
		Th[ 2 ]: 04 = 016
		Th[ 0 ]: 00 = 000
		Th[ 3 ]: 06 = 036
		Th[ 1 ]: 02 = 004
		Th[ 2 ]: 05 = 025
		Th[ 0 ]: 01 = 001
		Th[ 3 ]: 07 = 049
		Th[ 1 ]: 03 = 009
		Th[ 0 ]: 08 = 064
		Th[ 1 ]: 10 = 100
		Th[ 0 ]: 09 = 081
		Th[ 2 ]: 12 = 144
		Th[ 3 ]: 14 = 196
		Th[ 1 ]: 11 = 121
		Th[ 2 ]: 13 = 169
		Th[ 3 ]: 15 = 225
	\end{verbatim}

\subsection{Correções} 
	Para que o resultado do programa seja correcto deve ser adicionado o bloco ordered e neste caso só é necessário colocá-lo para a linha 10 porque você quer imprimir em ordem, mas também poderia ser colocado para as linhas 9 e 10.
	\begin{lstlisting} 
		#include <stdio.h>
		#include <omp.h>
		#define SIZE 16

		int main(){
			int A[ SIZE ] , i ;
			#pragma omp parallel for schedule( static , 2 ) num_threads( 4 ) ordered
			for( i = 0 ; i < SIZE ; i++){
				A[ i ] = i * i ;
				#pragma omp ordered
				{
					printf( "Th[ %d ]: %02d = %03d\n" , omp_get_thread_num() , i , A[ i ] ) ;
				}
			}
			return 0 ;
		}
	\end{lstlisting}
 
\subsection{Conclusões} 
	A diretiva ordered deve ser sempre usada com seu bloco ordered para que o compilador pode saber quais tarefas devem ser executadas em ordem, caso contrário, os resultados poderiam não ser corretos. Quando é bem utilizada, esta diretiva garante que só um thread por bloco ordered esté em execução enquanto os outros esperam \cite{Lawrence14}.

\clearpage 
 \section{Exercício 2} 
\label{sec:tab} 
\textbf{Modifique o programa mult.c, que realiza a multiplicação de 2 matrizes. Modifique este código para que ele realize a multiplicação utilizando as primitivas de paralelização de OpenMP. Compare o desempenho com 1, 2, 3 4, 8 e 16 threads. Tente realizar a paralelização no laço for das variáveis i, j e k, explicando no relatório se o comportamento obtido está correto ou não. Apresente e descreva no relatório grafos, tabelas e estatísticas dos tempos de execução.
\begin{itemize} 
\item Compare o desempenho obtido, explicando por que melhorou ou piorou e compare também a execução do programa em sua versão sequencial. 
\item Um dos objetivos e verificar se algum overhead e inserido pelo ambiente de execução (runtime OpenMP) quando a versão paralela do programa em OpenMP executa apenas com uma (1) thread, comparando-se com a versão sequencial (mult.c). 
\item Esse programa deve ser executado em pelo menos dois processadores diferentes, para efeitos de encontrar os intervalos de confiança cada execução deve ser repetida pelo menos 10 vezes. 
\item Outras informações que julgarem pertinentes ao contexto do trabalho podem ser adicionadas, e poderão ser somadas como pontos adicionais do EP.
\end{itemize}
}
\subsection{Experimentos} 
Os experimentos realizados neste exercício podem ser separados em duas categorias: a primeira consta da adição de diretivas OpenMP para criar as zonas paralelas, a segunda consta tanto da adição das  diretivas como de câmbios no mesmo código para optimizar o uso dos recursos. Cada uma de estas categorias conta com 4 programas diferentes: o programa sequencial, o programa com paralelização no laço da variável i, o programa com paralelização no laço da variável j, e finalmente, o programa com paralelização no laço da variável k. Cada programa, a excepção do programa sequencial, foi executado com diferentes números de threads.  
 
Algumas das características dos experimentos são: 
\begin{itemize} 
\item Otimização de código. Certas partes do programa original mult.c para melhorar o uso dos recursos. Estas otimizações foram dois: o uso de uma variável temporal, $tmp$ para armazenar a suma das multiplicações e o uso de um método $transpose$ para obter um acesso sequencial da matriz $b$. 
\item Zonas paralelas. Diferentes zonas foram criadas no laço das variáveis i, j e k.  
\item Número de threads. O desempenho foi avaliado com 1, 2, 3, 4, 8 e 16 threads.   
\item Processadores. Foram utilizados o: Intel CoreTM i5-3317U CPU @ 1.70GHz x 4 e o AMD A4-1200 APU with Radeon(TM) HD Graphics 1.00Ghz.
\end{itemize} 
O código de cada um dos experimentos pode ser observado no anexo 1 e 2.  
\subsection{Resultados} 
Os resultados nos tempos de execução dos experimentos da primeira categoria, sem otimização de código, foram os seguentes: 

\subsection{Tabela mais elaborada}
\begin{table}[htb]
\begin{center}
\begin{tabular}{|l|r|c|r|r|} \hline
            & \multicolumn{2}{|c|}{{CCF preconditioner}} & \multicolumn{2}{|c|}{{Number of nonzeros}} \\ \cline{2-5}
{Problem}   & \multicolumn{1}{|c|}{$\eta$}  & \multicolumn{1}{|c|}{$ \frac{n(AD^{-1}A^T)}{nrow}$} & \multicolumn{1}{|c|}{FCC} & \multicolumn{1}{|c|}{Cholesky}  \\ \hline \hline
ELS-19    &  -11 & 31 &  87750  & 3763686  \\\hline
SCR20     &  -12 & 31 &  103179 & 2591752  \\\hline
NUG15     &  -12 & 32 &  54786  & 6350444 \\\hline
PDS-20    &   15 & 5  &  625519 & 7123636\\\hline
\end{tabular}
\caption{Título da Tabela.}   
\label{tabn}
\end{center}
\end{table}
 
Os resultados nos tempos de execução dos experimentos da segunda categoria, com otimização de código, foram os seguentes: 

\subsection{Tabela mais elaborada}
\begin{table}[htb]
\begin{center}
\begin{tabular}{|l|r|c|r|r|} \hline
            & \multicolumn{2}{|c|}{{CCF preconditioner}} & \multicolumn{2}{|c|}{{Number of nonzeros}} \\ \cline{2-5}
{Problem}   & \multicolumn{1}{|c|}{$\eta$}  & \multicolumn{1}{|c|}{$ \frac{n(AD^{-1}A^T)}{nrow}$} & \multicolumn{1}{|c|}{FCC} & \multicolumn{1}{|c|}{Cholesky}  \\ \hline \hline
ELS-19    &  -11 & 31 &  87750  & 3763686  \\\hline
SCR20     &  -12 & 31 &  103179 & 2591752  \\\hline
NUG15     &  -12 & 32 &  54786  & 6350444 \\\hline
PDS-20    &   15 & 5  &  625519 & 7123636\\\hline
\end{tabular}
\caption{Título da Tabela.}   
\label{tabn2}
\end{center}
\end{table}

Um grafo de todos os tempos de execução pode ser observado na figura ~\ref{fig:pdsmodel} 
 
\begin{figure}[htb] 
\centering 
 
\includegraphics[height=14cm]{Images/figura} 
\label{fig:pdsmodel} 
\end{figure} 
 
\subsection{Conclusões} 
 
\clearpage 
\section{Conclusões} 
Apresentar as conclusões finais. 
 
\clearpage 
 
\bibliographystyle{plain}   
\bibliography{bibliografia.bib} 
\appendix 
 
\section{Anexo I} 
\label{anex1} 
 
Código do programa mult.c sequencial com trocas para a medição do tempo. 
\begin{verbatim} 
/*
ID: diana.n1
PROG: MultSeqCodeChange
LANG: C++
*/

#include <stdio.h>
#include <assert.h>
#include <stdlib.h>
#include <assert.h>
#include <time.h>
#include "omp.h"

void transpose(int n, long ** m){
	long tmp;
	for (int i = 0; i < n; i++){
		for (int j = i+1; j < n; j++){
			tmp = m[i][j];
			m[i][j] = m[j][i];
			m[j][i] = tmp;
		}
	}	
}

int main(int argc, char **argv) {
	double start, end; 
	start = omp_get_wtime();
	long **a, **b, **c;
    int N = 500;
	
    if (argc == 2) {
      N = atoi (argv[1]);
      assert (N > 0);
    }

    int i,j,k,mul=5;
    long col_sum = N * (N-1) / 2, tmp;
	
		
	a = (long **)malloc (N * sizeof(long *));
	b = (long **)malloc (N * sizeof(long *));
	c = (long **)malloc (N * sizeof(long *));
	for (i=0; i<N; i++) {
	  a[i] = (long *)malloc (N * sizeof(long));
	  b[i] = (long *)malloc (N * sizeof(long));
	  c[i] = (long *)malloc (N * sizeof(long));
	}


	for (i=0; i<N; i++){
	  for (j=0; j<N; j++) {
		a[i][j] = i*mul;
		b[i][j] = i;
		c[i][j] = 0;
	  }
	}

	printf ("Matrix generation finished.\n");         

	transpose(N, b);
	for (i=0; i<N; i++){
	  	for (j=0; j<N; j++){
			tmp = 0;
			for (k=0; k<N; k++){
				tmp += a[i][k] * b[j][k];
			}
			c[i][j] = tmp;
	  	}
	}

	printf ("Multiplication finished.\n");         
	
	for (i=0; i<N; i++)
	  for (j=0; j<N; j++)
		assert ( c[i][j] == i*mul * col_sum);  
    printf ("Test finished.\n");         

	end = omp_get_wtime();
	printf("Time: %lf.\n", end-start);
}
\end{verbatim}
 
Código do programa mult.c com paralelização no laço da variável i. 
\begin{verbatim} 
/*
ID: diana.n1
PROG: MultParalleli
LANG: C++
*/

#include <stdio.h>
#include <assert.h>
#include <stdlib.h>
#include <assert.h>
#include <time.h>
#include "omp.h"

int main(int argc, char **argv) {
	double start, end; 
	start = omp_get_wtime();
    int nthreads, tid, chunk = 10;
	
	long **a, **b, **c;
    int N = 500;
	
    if (argc == 2) {
      N = atoi (argv[1]);
      assert (N > 0);
    }

    int i,j,k,mul=5;
    long col_sum = N * (N-1) / 2;
	
	a = (long **)malloc (N * sizeof(long *));
	b = (long **)malloc (N * sizeof(long *));
	c = (long **)malloc (N * sizeof(long *));
	
	for (i=0; i<N; i++) {
	  a[i] = (long *)malloc (N * sizeof(long));
	  b[i] = (long *)malloc (N * sizeof(long));
	  c[i] = (long *)malloc (N * sizeof(long));
	}

	#pragma omp parallel shared (a,b,c,nthreads, chunk) private (i, j,k,tid) 
	{
		tid = omp_get_thread_num();
		#pragma omp single
			printf("Number threads = %d\n", omp_get_num_threads());

		#pragma omp for schedule(static, chunk)
		for (i=0; i<N; i++){
			for (j=0; j<N; j++) {
				a[i][j] = i*mul;
				b[i][j] = i;
				c[i][j] = 0;
	  		}
		}
		#pragma omp single
			printf ("Matrix generation finished.\n");         
		
		#pragma omp for schedule(static, chunk)
			for (i=0; i<N; i++){
				for (j=0; j<N; j++){
					for (k=0; k<N; k++){
						c[i][j] += a[i][k] * b[k][j];
					}
		  		}
			}
		
		#pragma omp single
			printf ("Multiplication finished.\n");         
	
		#pragma omp for schedule(static, chunk)
			for (i=0; i<N; i++){
			  	for (j=0; j<N; j++){
					assert ( c[i][j] == i*mul * col_sum);  
				}
			}
		#pragma omp single
			printf ("Test finished.\n");         
	}

	end = omp_get_wtime();
	printf("Time: %lf.\n", end-start);
}

\end{verbatim} 
 
Código do programa mult.c com paralelização no laço da variável j. 
\begin{verbatim} 
/*
ID: diana.n1
PROG: MultParallelj
LANG: C++
*/

#include <stdio.h>
#include <assert.h>
#include <stdlib.h>
#include <assert.h>
#include <time.h>
#include "omp.h"

int main(int argc, char **argv) {
	double start, end; 
	start = omp_get_wtime();
    int nthreads, tid, chunk = 10;
	
	long **a, **b, **c;
    int N = 500;
	
    if (argc == 2) {
      N = atoi (argv[1]);
      assert (N > 0);
    }

    int i,j,k,mul=5;
    long col_sum = N * (N-1) / 2;
	
	a = (long **)malloc (N * sizeof(long *));
	b = (long **)malloc (N * sizeof(long *));
	c = (long **)malloc (N * sizeof(long *));
	
	for (i=0; i<N; i++) {
	  a[i] = (long *)malloc (N * sizeof(long));
	  b[i] = (long *)malloc (N * sizeof(long));
	  c[i] = (long *)malloc (N * sizeof(long));
	}

	#pragma omp parallel shared (a,b,c,nthreads, chunk) private (i, j,k,tid) 
	{
		tid = omp_get_thread_num();
		#pragma omp single
			printf("Number threads = %d\n", omp_get_num_threads());

		#pragma omp for schedule(static, chunk)
		for (i=0; i<N; i++){
			for (j=0; j<N; j++) {
				a[i][j] = i*mul;
				b[i][j] = i;
				c[i][j] = 0;
	  		}
		}
		#pragma omp single
			printf ("Matrix generation finished.\n");         
		
		for (i=0; i<N; i++){
			#pragma omp for schedule(static, chunk)
				for (j=0; j<N; j++){
					for (k=0; k<N; k++){
						c[i][j] += a[i][k] * b[k][j];
					}
		  		}
		}
		
		#pragma omp single
			printf ("Multiplication finished.\n");         
	
		#pragma omp for schedule(static, chunk)
			for (i=0; i<N; i++){
			  	for (j=0; j<N; j++){
					assert ( c[i][j] == i*mul * col_sum);  
				}
			}
		#pragma omp single
			printf ("Test finished.\n");         
	}

	end = omp_get_wtime();
	printf("Time: %lf.\n", end-start);
}

\end{verbatim} 
 
Código do programa mult.c com paralelização no laço da variável k. 
\begin{verbatim} 
/*
ID: diana.n1
PROG: MultParallelk
LANG: C++
*/

#include <stdio.h>
#include <assert.h>
#include <stdlib.h>
#include <assert.h>
#include <time.h>
#include "omp.h"

int main(int argc, char **argv) {
	double start, end; 
	start = omp_get_wtime();
    int nthreads, tid, chunk = 10;
	
	long **a, **b, **c;
    int N = 500;
	
    if (argc == 2) {
      N = atoi (argv[1]);
      assert (N > 0);
    }

    int i,j,k,mul=5;
    long col_sum = N * (N-1) / 2;
	long temp;
	
	a = (long **)malloc (N * sizeof(long *));
	b = (long **)malloc (N * sizeof(long *));
	c = (long **)malloc (N * sizeof(long *));
	
	for (i=0; i<N; i++) {
	  a[i] = (long *)malloc (N * sizeof(long));
	  b[i] = (long *)malloc (N * sizeof(long));
	  c[i] = (long *)malloc (N * sizeof(long));
	}

	#pragma omp parallel shared (a,b,c,nthreads, chunk, temp) private (i, j,k,tid)
	{
		tid = omp_get_thread_num();
		#pragma omp single
			printf("Number threads = %d\n", omp_get_num_threads());

		#pragma omp for schedule(static, chunk)
		for (i=0; i<N; i++){
			for (j=0; j<N; j++) {
				a[i][j] = i*mul;
				b[i][j] = i;
				c[i][j] = 0;
	  		}
		}
		#pragma omp single
			printf ("Matrix generation finished.\n");         
		
		for (i=0; i<N; i++){
			for (j=0; j<N; j++){
				#pragma omp single
					temp = 0;
				#pragma omp for schedule(static, chunk) reduction (+:temp) 
					for (k=0; k<N; k++){
						temp += a[i][k] * b[k][j];
					}
				#pragma omp single
					c[i][j] = temp;
		  	}
		}
		
		#pragma omp single
			printf ("Multiplication finished.\n");         
	
		#pragma omp for schedule(static, chunk)
			for (i=0; i<N; i++){
			  	for (j=0; j<N; j++){
					assert ( c[i][j] == i*mul * col_sum);  
				}
			}
		#pragma omp single
			printf ("Test finished.\n");         
	}

	end = omp_get_wtime();
	printf("Time: %lf.\n", end-start);
}

\end{verbatim} 
 
\section{Anexo II} 
\label{anex2} 
 
Código do programa mult.c sequencial com optimizações de código. 
\begin{verbatim} 
/*
ID: diana.n1
PROG: MultSeqCodeChange
LANG: C++
*/

#include <stdio.h>
#include <assert.h>
#include <stdlib.h>
#include <assert.h>
#include <time.h>
#include "omp.h"

void transpose(int n, long ** m){
	long tmp;
	for (int i = 0; i < n; i++){
		for (int j = i+1; j < n; j++){
			tmp = m[i][j];
			m[i][j] = m[j][i];
			m[j][i] = tmp;
		}
	}	
}

int main(int argc, char **argv) {
	double start, end; 
	start = omp_get_wtime();
	long **a, **b, **c;
    int N = 500;
	
    if (argc == 2) {
      N = atoi (argv[1]);
      assert (N > 0);
    }

    int i,j,k,mul=5;
    long col_sum = N * (N-1) / 2, tmp;
	
		
	a = (long **)malloc (N * sizeof(long *));
	b = (long **)malloc (N * sizeof(long *));
	c = (long **)malloc (N * sizeof(long *));
	for (i=0; i<N; i++) {
	  a[i] = (long *)malloc (N * sizeof(long));
	  b[i] = (long *)malloc (N * sizeof(long));
	  c[i] = (long *)malloc (N * sizeof(long));
	}


	for (i=0; i<N; i++){
	  for (j=0; j<N; j++) {
		a[i][j] = i*mul;
		b[i][j] = i;
		c[i][j] = 0;
	  }
	}

	printf ("Matrix generation finished.\n");         

	transpose(N, b);
	for (i=0; i<N; i++){
	  	for (j=0; j<N; j++){
			tmp = 0;
			for (k=0; k<N; k++){
				tmp += a[i][k] * b[j][k];
			}
			c[i][j] = tmp;
	  	}
	}

	printf ("Multiplication finished.\n");         
	
	for (i=0; i<N; i++)
	  for (j=0; j<N; j++)
		assert ( c[i][j] == i*mul * col_sum);  
    printf ("Test finished.\n");         

	end = omp_get_wtime();
	printf("Time: %lf.\n", end-start);
}

\end{verbatim} 
 
Código do programa mult.c com paralelização no laço da variável i com optimizações de código. 
\begin{verbatim} 

/*
ID: diana.n1
PROG: MultParalleliCodeChange
LANG: C++
*/

#include <stdio.h>
#include <assert.h>
#include <stdlib.h>
#include <assert.h>
#include <time.h>
#include "omp.h"

void transpose(int n, long ** m){
	long tmp;
	for (int i = 0; i < n; i++){
		for (int j = i+1; j < n; j++){
			tmp = m[i][j];
			m[i][j] = m[j][i];
			m[j][i] = tmp;
		}
	}	
}

int main(int argc, char **argv) {
	double start, end; 
	start = omp_get_wtime();
    int nthreads, tid, chunk = 10;
	
	long **a, **b, **c;
    int N = 500;
	
    if (argc == 2) {
      N = atoi (argv[1]);
      assert (N > 0);
    }

    int i,j,k,mul=5;
    long col_sum = N * (N-1) / 2, tmp;
	
	a = (long **)malloc (N * sizeof(long *));
	b = (long **)malloc (N * sizeof(long *));
	c = (long **)malloc (N * sizeof(long *));
	
	for (i=0; i<N; i++) {
	  a[i] = (long *)malloc (N * sizeof(long));
	  b[i] = (long *)malloc (N * sizeof(long));
	  c[i] = (long *)malloc (N * sizeof(long));
	}

	#pragma omp parallel shared (a,b,c,nthreads, chunk) private (i, j,k,tid, tmp) 
	{
		tid = omp_get_thread_num();
		
		#pragma omp single
			printf("Number threads = %d\n", omp_get_num_threads());

		#pragma omp for schedule(static, chunk)
		for (i=0; i<N; i++){
			for (j=0; j<N; j++) {
				a[i][j] = i*mul;
				b[i][j] = i;
				c[i][j] = 0;
	  		}
		}
		
		#pragma omp single
			printf ("Matrix generation finished.\n");         
	
		#pragma omp single
			transpose(N, b);

		#pragma omp for schedule(static, chunk)
			for (i=0; i<N; i++){
				for (j=0; j<N; j++){	
					tmp = 0;
					for (k=0; k<N; k++){

						tmp += a[i][k] * b[j][k];
					}
					c[i][j] = tmp;
		  		}
			}
		
		#pragma omp single
			printf ("Multiplication finished.\n");         
	
		#pragma omp for schedule(static, chunk)
			for (i=0; i<N; i++){
			  	for (j=0; j<N; j++){
					assert ( c[i][j] == i*mul * col_sum);  
				}
			}
		#pragma omp single
			printf ("Test finished.\n");         
	}

	end = omp_get_wtime();
	printf("Time: %lf.\n", end-start);
}

\end{verbatim} 
 
Código do programa mult.c com paralelização no laço da variável j com optimizações de código. 
\begin{verbatim} 
/*
ID: diana.n1
PROG: MultParalleljCodeChange
LANG: C++
*/

#include <stdio.h>
#include <assert.h>
#include <stdlib.h>
#include <assert.h>
#include <time.h>
#include "omp.h"

void transpose(int n, long ** m){
	long tmp;
	for (int i = 0; i < n; i++){
		for (int j = i+1; j < n; j++){
			tmp = m[i][j];
			m[i][j] = m[j][i];
			m[j][i] = tmp;
		}
	}	
}

int main(int argc, char **argv) {
	double start, end; 
	start = omp_get_wtime();
    int nthreads, tid, chunk = 10;
	
	long **a, **b, **c;
    int N = 500;
	
    if (argc == 2) {
      N = atoi (argv[1]);
      assert (N > 0);
    }

    int i,j,k,mul=5;
    long col_sum = N * (N-1) / 2, tmp;
	
	a = (long **)malloc (N * sizeof(long *));
	b = (long **)malloc (N * sizeof(long *));
	c = (long **)malloc (N * sizeof(long *));
	
	for (i=0; i<N; i++) {
	  a[i] = (long *)malloc (N * sizeof(long));
	  b[i] = (long *)malloc (N * sizeof(long));
	  c[i] = (long *)malloc (N * sizeof(long));
	}

	#pragma omp parallel shared (a,b,c,nthreads, chunk) private (i,  j, k, tid, tmp) 
	{
		tid = omp_get_thread_num();
		#pragma omp single
			printf("Number threads = %d\n", omp_get_num_threads());

		#pragma omp for schedule(static, chunk)
		for (i=0; i<N; i++){
			for (j=0; j<N; j++) {
				a[i][j] = i*mul;
				b[i][j] = i;
				c[i][j] = 0;
	  		}
		}
		#pragma omp single
			printf ("Matrix generation finished.\n");      

		#pragma omp single
			transpose(N, b);
		
		for (i=0; i<N; i++){
			#pragma omp for schedule(static, chunk)
				for (j=0; j<N; j++){
					tmp = 0;
					for (k=0; k<N; k++){
						tmp += a[i][k] * b[j][k];
					}
					c[i][j] = tmp;
		  		}
		}
		
		#pragma omp single
			printf ("Multiplication finished.\n");         
	
		#pragma omp for schedule(static, chunk)
			for (i=0; i<N; i++){
			  	for (j=0; j<N; j++){
					assert ( c[i][j] == i*mul * col_sum);  
				}
			}
		#pragma omp single
			printf ("Test finished.\n");         
	}

	end = omp_get_wtime();
	printf("Time: %lf.\n", end-start);
}

\end{verbatim} 
 
Código do programa mult.c com paralelização no laço da variável k com optimizações de código. 
\begin{verbatim} 
/*
ID: diana.n1
PROG: MultParallelkCodeChange
LANG: C++
*/

#include <stdio.h>
#include <assert.h>
#include <stdlib.h>
#include <assert.h>
#include <time.h>
#include "omp.h"

void transpose(int n, long ** m){
	long tmp;
	for (int i = 0; i < n; i++){
		for (int j = i+1; j < n; j++){
			tmp = m[i][j];
			m[i][j] = m[j][i];
			m[j][i] = tmp;
		}
	}	
}

int main(int argc, char **argv) {
	double start, end; 
	start = omp_get_wtime();
    int nthreads, tid, chunk = 10;
	
	long **a, **b, **c;
    int N = 500;
	
    if (argc == 2) {
      N = atoi (argv[1]);
      assert (N > 0);
    }

    int i,j,k,mul=5;
    long col_sum = N * (N-1) / 2, tmp;
	
	a = (long **)malloc (N * sizeof(long *));
	b = (long **)malloc (N * sizeof(long *));
	c = (long **)malloc (N * sizeof(long *));
	
	for (i=0; i<N; i++) {
	  a[i] = (long *)malloc (N * sizeof(long));
	  b[i] = (long *)malloc (N * sizeof(long));
	  c[i] = (long *)malloc (N * sizeof(long));
	}

	#pragma omp parallel shared (a,b,c,nthreads, chunk, tmp) private (i, j,k,tid)
	{
		tid = omp_get_thread_num();
		#pragma omp single
			printf("Number threads = %d\n", omp_get_num_threads());

		#pragma omp for schedule(static, chunk)
		for (i=0; i<N; i++){
			for (j=0; j<N; j++) {
				a[i][j] = i*mul;
				b[i][j] = i;
				c[i][j] = 0;
	  		}
		}
		#pragma omp single
			printf ("Matrix generation finished.\n");         
		
		#pragma omp single
			transpose(N, b);

		for (i=0; i<N; i++){
			for (j=0; j<N; j++){
				#pragma omp single
					tmp = 0;
				#pragma omp for schedule(static, chunk) reduction (+:tmp) 
					for (k=0; k<N; k++){
						tmp += a[i][k] * b[j][k];
					}
				#pragma omp single
					c[i][j] = tmp;
		  	}
		}
		
		#pragma omp single
			printf ("Multiplication finished.\n");         
	
		#pragma omp for schedule(static, chunk)
			for (i=0; i<N; i++){
			  	for (j=0; j<N; j++){
					assert ( c[i][j] == i*mul * col_sum);  
				}
			}
		#pragma omp single
			printf ("Test finished.\n");         
	}

	end = omp_get_wtime();
	printf("Time: %lf.\n", end-start);
}
\end{verbatim} 
 
\end{document} 
 
 
 
 
 
